{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0cd3803",
   "metadata": {},
   "source": [
    "# step2: RetrievalQA 체인 구현\n",
    "\n",
    "1. 2주차에서 만든 Document Pipeline 재사용\n",
    "2. Retriever 설정\n",
    "3. RetrievalQA 체인 구현 (LCEL 스타일)\n",
    "4. 기술 문서 Q&A 챗봇 인터페이스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6715d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from src.document_pipeline import DocumentPipeline\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff906d99",
   "metadata": {},
   "source": [
    "## 설정 파라미터\n",
    "\n",
    "검색 및 체인 파라미터를 상단에서 설정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever 설정\n",
    "SEARCH_TYPE = \"similarity\"\n",
    "TOP_K = 3\n",
    "\n",
    "# 벡터 저장소 설정\n",
    "VECTOR_STORE_TYPE = \"chroma\"\n",
    "CHROMA_PERSIST_DIR = \"./chroma_db\"\n",
    "FAISS_SAVE_DIR = \"./faiss_db\"\n",
    "\n",
    "print(f\"검색 타입: {SEARCH_TYPE}\")\n",
    "print(f\"Top K: {TOP_K}\")\n",
    "print(f\"벡터 저장소 타입: {VECTOR_STORE_TYPE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d9e24",
   "metadata": {},
   "source": [
    "## 1. 벡터 저장소 로드\n",
    "\n",
    "2주차에서 생성한 벡터 저장소를 로드합니다.\n",
    "ㅝ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2cfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DocumentPipeline()\n",
    "\n",
    "if VECTOR_STORE_TYPE == \"chroma\":\n",
    "    vectorstore = pipeline.load_chroma_store(CHROMA_PERSIST_DIR)\n",
    "    print(f\"Chroma 벡터 저장소 로드 완료: {CHROMA_PERSIST_DIR}\")\n",
    "elif VECTOR_STORE_TYPE == \"faiss\":\n",
    "    vectorstore = pipeline.load_faiss_store(FAISS_SAVE_DIR)\n",
    "    print(f\"FAISS 벡터 저장소 로드 완료: {FAISS_SAVE_DIR}\")\n",
    "else:\n",
    "    raise ValueError(f\"지원하지 않는 벡터 저장소 타입: {VECTOR_STORE_TYPE}\")\n",
    "\n",
    "print(f\"벡터 저장소 타입: {type(vectorstore).__name__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ade7b",
   "metadata": {},
   "source": [
    "## 2. Retriever 설정\n",
    "\n",
    "벡터 저장소로부터 retriever 객체를 생성합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97cd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=SEARCH_TYPE,\n",
    "    search_kwargs={\"k\": TOP_K}\n",
    ")\n",
    "\n",
    "print(f\"Retriever 생성 완료\")\n",
    "print(f\"  - 검색 타입: {SEARCH_TYPE}\")\n",
    "print(f\"  - Top K: {TOP_K}\")\n",
    "\n",
    "# 테스트 검색\n",
    "test_query = \"Tesla revenue\"\n",
    "test_docs = retriever.invoke(test_query)\n",
    "print(f\"\\n테스트 검색 ('{test_query}') 결과: {len(test_docs)}개 문서\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0d0c9",
   "metadata": {},
   "source": [
    "## 3. LLM 초기화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50df669",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_api_key = os.getenv(\"GPT_API_KEY\")\n",
    "llm = None\n",
    "\n",
    "if gpt_api_key:\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        api_key=gpt_api_key,\n",
    "        temperature=0\n",
    "    )\n",
    "    print(\"GPT LLM 초기화 완료\")\n",
    "else:\n",
    "    print(\"GPT_API_KEY가 없어서 LLM을 사용할 수 없습니다.\")\n",
    "    print(\"환경 변수를 설정해주세요.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8891d4",
   "metadata": {},
   "source": [
    "## 4. 프롬프트 설계\n",
    "\n",
    "역할/태도, 근거 사용, 출력 형식을 포함한 프롬프트를 설계합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서를 포맷팅합니다.\"\"\"\n",
    "    formatted_parts = []\n",
    "    sources = []\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        doc_type = doc.metadata.get('type', 'text')\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        page = doc.metadata.get('page', 'N/A')\n",
    "        \n",
    "        if doc_type == 'table':\n",
    "            caption = doc.metadata.get('caption', 'N/A')\n",
    "            original_table = doc.metadata.get('original_table', doc.page_content)\n",
    "            formatted_parts.append(f\"[문서 {i} - 표: {caption}]\\n{original_table}\")\n",
    "            sources.append({\n",
    "                'index': i,\n",
    "                'type': 'table',\n",
    "                'caption': caption,\n",
    "                'source': source,\n",
    "                'page': page\n",
    "            })\n",
    "        else:\n",
    "            formatted_parts.append(f\"[문서 {i}]\\n{doc.page_content}\")\n",
    "            sources.append({\n",
    "                'index': i,\n",
    "                'type': 'text',\n",
    "                'source': source,\n",
    "                'page': page\n",
    "            })\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_parts), sources\n",
    "\n",
    "template = \"\"\"당신은 주어진 기술 문서에 기반해서만 답변하는 AI 어시스턴트입니다.\n",
    "\n",
    "다음 문서들을 참고하여 질문에 답변해주세요. 반드시 제공된 문서 내용을 기반으로 답변하고, 문서에 없는 내용은 '문서에 정보가 없습니다'라고 답하세요.\n",
    "\n",
    "문서:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변 형식:\n",
    "1. 1줄 요약 답변\n",
    "2. 상세 답변\n",
    "3. 근거가 된 문서 정보 (문서 번호, 출처, 페이지/섹션)\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38dd383",
   "metadata": {},
   "source": [
    "## 5. RetrievalQA 체인 구현 (LCEL 스타일)\n",
    "\n",
    "retriever | prompt | llm 형태로 파이프라인을 구성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f127274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_chain(retriever, prompt, llm):\n",
    "    \"\"\"RAG 체인을 생성합니다 (LCEL 스타일).\"\"\"\n",
    "    def format_context(docs):\n",
    "        formatted_text, _ = format_docs(docs)\n",
    "        return formatted_text\n",
    "    \n",
    "    chain = (\n",
    "        {\"context\": retriever | format_context, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return chain\n",
    "\n",
    "if llm:\n",
    "    rag_chain = create_rag_chain(retriever, prompt, llm)\n",
    "    print(\"RetrievalQA 체인 생성 완료 (LCEL 스타일)\")\n",
    "    print(\"체인 구조: retriever | format_context | prompt | llm | StrOutputParser\")\n",
    "else:\n",
    "    print(\"LLM이 없어서 체인을 생성할 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f5925",
   "metadata": {},
   "source": [
    "## 6. 체인 테스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if llm:\n",
    "    test_question = \"What is Tesla's revenue in Q3 2025?\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"질문:\", test_question)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 검색된 문서 확인\n",
    "    retrieved_docs = retriever.invoke(test_question)\n",
    "    print(f\"\\n검색된 문서 수: {len(retrieved_docs)}\")\n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        doc_type = doc.metadata.get('type', 'text')\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        page = doc.metadata.get('page', 'N/A')\n",
    "        if doc_type == 'table':\n",
    "            caption = doc.metadata.get('caption', 'N/A')\n",
    "            print(f\"  [{i}] 표: {caption} (출처: {source}, 페이지: {page})\")\n",
    "        else:\n",
    "            print(f\"  [{i}] 텍스트 (출처: {source}, 페이지: {page})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"답변:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    answer = rag_chain.invoke(test_question)\n",
    "    print(answer)\n",
    "else:\n",
    "    print(\"LLM이 없어서 테스트를 수행할 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046a0ec",
   "metadata": {},
   "source": [
    "## 7. 기술 문서 Q&A 챗봇 인터페이스\n",
    "\n",
    "콘솔 기반 인터페이스를 구현합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc644eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_interface(rag_chain, retriever):\n",
    "    \"\"\"Q&A 챗봇 인터페이스\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"기술 문서 Q&A 챗봇\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"질문을 입력하세요. 종료하려면 'quit', 'exit', 'q'를 입력하세요.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"질문: \").strip()\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', 'q', '']:\n",
    "            print(\"챗봇을 종료합니다.\")\n",
    "            break\n",
    "        \n",
    "        if not question:\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"검색 중...\")\n",
    "        \n",
    "        try:\n",
    "            retrieved_docs = retriever.invoke(question)\n",
    "            print(f\"검색된 문서: {len(retrieved_docs)}개\\n\")\n",
    "            \n",
    "            print(\"답변 생성 중...\\n\")\n",
    "            answer = rag_chain.invoke(question)\n",
    "            \n",
    "            print(\"=\"*60)\n",
    "            print(\"답변:\")\n",
    "            print(\"=\"*60)\n",
    "            print(answer)\n",
    "            \n",
    "            print(\"\\n\" + \"-\"*60)\n",
    "            print(\"참고 문서:\")\n",
    "            for i, doc in enumerate(retrieved_docs, 1):\n",
    "                doc_type = doc.metadata.get('type', 'text')\n",
    "                source = doc.metadata.get('source', 'N/A')\n",
    "                page = doc.metadata.get('page', 'N/A')\n",
    "                if doc_type == 'table':\n",
    "                    caption = doc.metadata.get('caption', 'N/A')\n",
    "                    print(f\"  [{i}] 표: {caption}\")\n",
    "                    print(f\"      출처: {source} (페이지: {page})\")\n",
    "                else:\n",
    "                    print(f\"  [{i}] 텍스트\")\n",
    "                    print(f\"      출처: {source} (페이지: {page})\")\n",
    "                    print(f\"      내용 미리보기: {doc.page_content[:100]}...\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "if llm:\n",
    "    print(\"챗봇 인터페이스를 시작하려면 아래 셀을 실행하세요.\")\n",
    "    print(\"chat_interface(rag_chain, retriever)\")\n",
    "else:\n",
    "    print(\"LLM이 없어서 챗봇 인터페이스를 사용할 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b71f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 인터페이스 실행\n",
    "if llm:\n",
    "    chat_interface(rag_chain, retriever)\n",
    "else:\n",
    "    print(\"LLM이 없어서 챗봇을 실행할 수 없습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
