{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c416e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/study/learning_langchain/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path(\"../\")\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from typing import List, TypedDict, Literal\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from src.utils import load_vectorstore, load_llm\n",
    "from src.storage import Storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8daf063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 저장소 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/study/learning_langchain/weekly_project/../src/utils.py:30: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 저장소 로드 완료\n",
      "\n",
      "Storage 초기화 중...\n",
      "Storage 초기화 완료\n",
      "\n",
      "LLM 초기화 중...\n",
      "LLM 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "db_path = \"../data/db\"\n",
    "storage_path = \"../data/processed\"\n",
    "\n",
    "print(\"벡터 저장소 로드 중...\")\n",
    "vectorstore = load_vectorstore(db_path)\n",
    "print(\"벡터 저장소 로드 완료\")\n",
    "\n",
    "print(\"\\nStorage 초기화 중...\")\n",
    "storage = Storage(storage_path)\n",
    "print(\"Storage 초기화 완료\")\n",
    "\n",
    "print(\"\\nLLM 초기화 중...\")\n",
    "llm = load_llm()\n",
    "if llm:\n",
    "    print(\"LLM 초기화 완료\")\n",
    "else:\n",
    "    print(\"LLM 초기화 실패 (GPT_API_KEY 확인 필요)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07891919",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    intent: str\n",
    "    query: str\n",
    "    context: str\n",
    "    intent_history: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c227465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_intent(state: ChatState) -> ChatState:\n",
    "    query = state.get(\"query\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    messages.append(HumanMessage(content=query))\n",
    "    state[\"messages\"] = messages\n",
    "    \n",
    "    if not llm:\n",
    "        state[\"intent\"] = \"SMALL_TALK\"\n",
    "        return state\n",
    "    \n",
    "    prompt = f\"\"\"다음 사용자 발화를 보고, 의도를 아래 중 하나로 골라라: DOC_QA, SUMMARY, SMALL_TALK. 다른 말은 하지 말고, 태그만 출력해라.\n",
    "\n",
    "사용자 발화: {query}\n",
    "\n",
    "의도:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        intent = response.content.strip() if hasattr(response, 'content') else str(response).strip()\n",
    "        \n",
    "        if intent not in [\"DOC_QA\", \"SUMMARY\", \"SMALL_TALK\"]:\n",
    "            if any(keyword in query.lower() for keyword in [\"요약\", \"정리\", \"핵심\", \"요점\"]):\n",
    "                intent = \"SUMMARY\"\n",
    "            elif any(keyword in query.lower() for keyword in [\"안녕\", \"뭐야\", \"누구\", \"소개\"]):\n",
    "                intent = \"SMALL_TALK\"\n",
    "            else:\n",
    "                intent = \"DOC_QA\"\n",
    "        \n",
    "        state[\"intent\"] = intent\n",
    "    except Exception as e:\n",
    "        print(f\"의도 분류 오류: {e}\")\n",
    "        state[\"intent\"] = \"SMALL_TALK\"\n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e40c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query: str, k: int = 5) -> List[Document]:\n",
    "    return vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "def load_original_content(doc: Document) -> str:\n",
    "    doc_type = doc.metadata.get('type', 'text')\n",
    "    \n",
    "    if doc_type == 'table':\n",
    "        table_id = doc.metadata.get('table_id')\n",
    "        if table_id:\n",
    "            table_data = storage.get_table(table_id)\n",
    "            if table_data:\n",
    "                markdown = table_data.get('markdown', '')\n",
    "                description = table_data.get('description', '')\n",
    "                return f\"{description}\\n{markdown}\" if description else markdown\n",
    "    else:\n",
    "        chunk_id = doc.metadata.get('chunk_id')\n",
    "        text_id = doc.metadata.get('text_id') or f'text_{chunk_id}' if chunk_id is not None else None\n",
    "        \n",
    "        if text_id:\n",
    "            text_data = storage.get_text(text_id)\n",
    "            if text_data:\n",
    "                return text_data.get('original_text', doc.page_content)\n",
    "    \n",
    "    return doc.page_content\n",
    "\n",
    "def build_context(docs: List[Document]) -> str:\n",
    "    context_parts = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        original_content = load_original_content(doc)\n",
    "        doc_type = doc.metadata.get('type', 'text')\n",
    "        \n",
    "        if doc_type == 'table':\n",
    "            table_id = doc.metadata.get('table_id', '')\n",
    "            context_parts.append(f\"[테이블 {i}: {table_id}]\\n{original_content}\")\n",
    "        else:\n",
    "            context_parts.append(f\"[텍스트 {i}]\\n{original_content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(context_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce94f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_qa_node(state: ChatState) -> ChatState:\n",
    "    query = state.get(\"query\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "    intent_history = state.get(\"intent_history\", [])\n",
    "    \n",
    "    docs = retrieve_documents(query, k=5)\n",
    "    context = build_context(docs)\n",
    "    state[\"context\"] = context\n",
    "    \n",
    "    if not llm:\n",
    "        answer = \"LLM이 설정되지 않아 답변을 생성할 수 없습니다.\"\n",
    "    else:\n",
    "        chat_history = \"\\n\".join([f\"{'사용자' if isinstance(msg, HumanMessage) else '어시스턴트'}: {msg.content}\" for msg in messages[:-1]])\n",
    "        \n",
    "        prompt = f\"\"\"다음 문서들을 참고하여 질문에 답변해주세요.\n",
    "\n",
    "참고 문서:\n",
    "{context}\n",
    "\n",
    "대화 기록:\n",
    "{chat_history}\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "답변:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            answer = response.content if hasattr(response, 'content') else str(response)\n",
    "        except Exception as e:\n",
    "            answer = f\"답변 생성 중 오류 발생: {e}\"\n",
    "    \n",
    "    messages.append(AIMessage(content=answer))\n",
    "    state[\"messages\"] = messages\n",
    "    \n",
    "    intent_history.append(\"DOC_QA\")\n",
    "    state[\"intent_history\"] = intent_history\n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33815541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_node(state: ChatState) -> ChatState:\n",
    "    query = state.get(\"query\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "    intent_history = state.get(\"intent_history\", [])\n",
    "    \n",
    "    doc_qa_conversations = []\n",
    "    human_count = 0\n",
    "    \n",
    "    for i, msg in enumerate(messages[:-1]):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            if human_count < len(intent_history) and intent_history[human_count] == \"DOC_QA\":\n",
    "                question = msg.content\n",
    "                if i + 1 < len(messages) and isinstance(messages[i + 1], AIMessage):\n",
    "                    answer = messages[i + 1].content\n",
    "                    doc_qa_conversations.append(f\"질문: {question}\\n답변: {answer}\")\n",
    "            human_count += 1\n",
    "    \n",
    "    if not llm:\n",
    "        answer = \"LLM이 설정되지 않아 요약을 생성할 수 없습니다.\"\n",
    "    elif not doc_qa_conversations:\n",
    "        answer = \"이전 대화에서 기술 문서 관련 질문(DOC_QA)이 없어 요약할 내용이 없습니다.\"\n",
    "    else:\n",
    "        doc_qa_content = \"\\n\\n\".join(doc_qa_conversations)\n",
    "        \n",
    "        prompt = f\"\"\"다음은 이전 대화에서 기술 문서 관련 질문과 답변들입니다. 이를 요약해주세요. 사용자의 요청에 맞게 요약해주세요.\n",
    "\n",
    "기술 문서 관련 대화 내용:\n",
    "{doc_qa_content}\n",
    "\n",
    "사용자 요청: {query}\n",
    "\n",
    "요약:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            answer = response.content if hasattr(response, 'content') else str(response)\n",
    "        except Exception as e:\n",
    "            answer = f\"요약 생성 중 오류 발생: {e}\"\n",
    "    \n",
    "    messages.append(AIMessage(content=answer))\n",
    "    state[\"messages\"] = messages\n",
    "    \n",
    "    intent_history.append(\"SUMMARY\")\n",
    "    state[\"intent_history\"] = intent_history\n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8fd8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_talk_node(state: ChatState) -> ChatState:\n",
    "    query = state.get(\"query\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "    intent_history = state.get(\"intent_history\", [])\n",
    "    \n",
    "    if not llm:\n",
    "        answer = \"안녕하세요! 저는 기술 문서를 기반으로 질문에 답변하는 AI 어시스턴트입니다.\"\n",
    "    else:\n",
    "        chat_history = \"\\n\".join([f\"{'사용자' if isinstance(msg, HumanMessage) else '어시스턴트'}: {msg.content}\" for msg in messages[-5:]])\n",
    "        \n",
    "        prompt = f\"\"\"당신은 친절한 AI 어시스턴트입니다. 사용자와 자연스럽게 대화하세요.\n",
    "\n",
    "대화 기록:\n",
    "{chat_history}\n",
    "\n",
    "사용자: {query}\n",
    "어시스턴트:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            answer = response.content if hasattr(response, 'content') else str(response)\n",
    "        except Exception as e:\n",
    "            answer = f\"답변 생성 중 오류 발생: {e}\"\n",
    "    \n",
    "    messages.append(AIMessage(content=answer))\n",
    "    state[\"messages\"] = messages\n",
    "    \n",
    "    intent_history.append(\"SMALL_TALK\")\n",
    "    state[\"intent_history\"] = intent_history\n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73363f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_edge_fn(state: ChatState) -> Literal[\"doc_qa\", \"summary\", \"small_talk\"]:\n",
    "    intent = state.get(\"intent\", \"SMALL_TALK\")\n",
    "    \n",
    "    if intent == \"DOC_QA\":\n",
    "        return \"doc_qa\"\n",
    "    elif intent == \"SUMMARY\":\n",
    "        return \"summary\"\n",
    "    else:\n",
    "        return \"small_talk\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf10b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래프 구성 완료\n"
     ]
    }
   ],
   "source": [
    "def build_graph():\n",
    "    workflow = StateGraph(ChatState)\n",
    "    \n",
    "    workflow.add_node(\"router\", classify_intent)\n",
    "    workflow.add_node(\"doc_qa\", doc_qa_node)\n",
    "    workflow.add_node(\"summary\", summary_node)\n",
    "    workflow.add_node(\"small_talk\", small_talk_node)\n",
    "    \n",
    "    workflow.set_entry_point(\"router\")\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"router\",\n",
    "        router_edge_fn,\n",
    "        {\n",
    "            \"doc_qa\": \"doc_qa\",\n",
    "            \"summary\": \"summary\",\n",
    "            \"small_talk\": \"small_talk\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(\"doc_qa\", END)\n",
    "    workflow.add_edge(\"summary\", END)\n",
    "    workflow.add_edge(\"small_talk\", END)\n",
    "    \n",
    "    memory = MemorySaver()\n",
    "    return workflow.compile(checkpointer=memory)\n",
    "\n",
    "app = build_graph()\n",
    "print(\"그래프 구성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "653b99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ASCII 그래프 ===\n",
      "                     +-----------+                       \n",
      "                     | __start__ |                       \n",
      "                     +-----------+                       \n",
      "                           *                             \n",
      "                           *                             \n",
      "                           *                             \n",
      "                      +--------+                         \n",
      "                      | router |.                        \n",
      "                   ...+--------+ ....                    \n",
      "               ....        .         ....                \n",
      "           ....            .             ....            \n",
      "         ..                .                 ..          \n",
      "+--------+          +------------+          +---------+  \n",
      "| doc_qa |*         | small_talk |          | summary |  \n",
      "+--------+ ****     +------------+       ***+---------+  \n",
      "               ****        *         ****                \n",
      "                   ****    *     ****                    \n",
      "                       **  *   **                        \n",
      "                      +---------+                        \n",
      "                      | __end__ |                        \n",
      "                      +---------+                        \n",
      "\n",
      "=== Mermaid 다이어그램 ===\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\trouter(router)\n",
      "\tdoc_qa(doc_qa)\n",
      "\tsummary(summary)\n",
      "\tsmall_talk(small_talk)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> router;\n",
      "\trouter -.-> doc_qa;\n",
      "\trouter -.-> small_talk;\n",
      "\trouter -.-> summary;\n",
      "\tdoc_qa --> __end__;\n",
      "\tsmall_talk --> __end__;\n",
      "\tsummary --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LangGraph 내장 시각화 방법\n",
    "print(\"=== ASCII 그래프 ===\")\n",
    "app.get_graph().print_ascii()\n",
    "\n",
    "print(\"\\n=== Mermaid 다이어그램 ===\")\n",
    "print(app.get_graph().draw_mermaid())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83147ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = \"test-user-1\"\n",
    "\n",
    "while True:\n",
    "    q = input(\"\\n질문: \").strip()\n",
    "    \n",
    "    if not q:\n",
    "        continue\n",
    "    \n",
    "    if q.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"종료합니다.\")\n",
    "        break\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    result = app.invoke(\n",
    "        {\"query\": q},\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    answer = result[\"messages\"][-1].content\n",
    "    intent = result.get('intent', 'UNKNOWN')\n",
    "    \n",
    "    print(f\"\\n[질문] {q}\")\n",
    "    print(f\"[의도: {intent}]\")\n",
    "    \n",
    "    if intent == \"DOC_QA\" and result.get(\"context\"):\n",
    "        print(f\"\\n[참고 문서]\\n{result['context']}\")\n",
    "        print(f\"\\n{'='*60}\")\n",
    "    \n",
    "    print(f\"\\n[답변]\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e4321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
